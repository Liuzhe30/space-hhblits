{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73893903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1742\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset name list\n",
    "import os\n",
    "hhm_path = 'data/hhblits_example/'\n",
    "pdb_path = 'data/pdb_example/'\n",
    "hhm_path_files = os.listdir(hhm_path)  \n",
    "name_list = []\n",
    "for fi in hhm_path_files: \n",
    "    hhm_name = fi.split('.')[0]\n",
    "    name_list.append(hhm_name)\n",
    "print(len(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c86e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot dict for proteins\n",
    "import numpy as np\n",
    "protein_dict = {'C':np.eye(20)[0], 'D':np.eye(20)[1], 'S':np.eye(20)[1], 'Q':np.eye(20)[3], 'K':np.eye(20)[4],\n",
    "        'I':np.eye(20)[5], 'P':np.eye(20)[6], 'T':np.eye(20)[7], 'F':np.eye(20)[8], 'N':np.eye(20)[9],\n",
    "        'G':np.eye(20)[10], 'H':np.eye(20)[11], 'L':np.eye(20)[12], 'R':np.eye(20)[13], 'W':np.eye(20)[14],\n",
    "        'A':np.eye(20)[15], 'V':np.eye(20)[16], 'E':np.eye(20)[17], 'Y':np.eye(20)[18], 'M':np.eye(20)[19]}\n",
    "#print(protein_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10203ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1742, 1024, 52)\n"
     ]
    }
   ],
   "source": [
    "# generate 1024 cut-off dataset\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "shhm_5A_mae_path = 'data/5A_mae_shhm/'\n",
    "all_sample_list = []\n",
    "with open(\"data/dataset_alphafold.txt\") as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        if(line[0] == '>'):\n",
    "            uniprot_id = line[1:].strip()\n",
    "            seq = file.readline().strip()\n",
    "            label = file.readline().strip()\n",
    "            feature_matrix = np.zeros([1024, 52], float) # 20+30+1,onehot+spacehhblits+mask+label\n",
    "            shhm_matrix = np.loadtxt(shhm_5A_mae_path + uniprot_id + \".shhm\")\n",
    "            # check seq length\n",
    "            if(len(seq) <= 1024):\n",
    "                for i in range(len(seq)):\n",
    "                    feature_matrix[i,0:20] = protein_dict[seq[i]]\n",
    "                    feature_matrix[i,20:50] = shhm_matrix[i,:]\n",
    "                    feature_matrix[i,-2] = 1\n",
    "                    feature_matrix[i,-1] = label[i]\n",
    "                for i in range(len(seq),1024):\n",
    "                    feature_matrix[i,-1] = 2 # padding for loss function\n",
    "            else: # cut off\n",
    "                for i in range(1024):\n",
    "                    feature_matrix[i,0:20] = protein_dict[seq[i]]\n",
    "                    feature_matrix[i,20:50] = shhm_matrix[i,:]\n",
    "                    feature_matrix[i,-2] = 1\n",
    "                    feature_matrix[i,-1] = label[i]\n",
    "        #print(feature_matrix.shape) #1024*52\n",
    "        all_sample_list.append(feature_matrix)\n",
    "        line = file.readline()\n",
    "all_sample = np.array(all_sample_list)\n",
    "print(all_sample.shape) # (1742, 1024, 52)\n",
    "np.save(\"data/dataset_5A_mae_shhm_1024.npy\", all_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2e6d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1742, 1024, 52)\n"
     ]
    }
   ],
   "source": [
    "# load 1024 cut-off dataset\n",
    "dataset = np.load(\"data/dataset_5A_mae_shhm_1024.npy\")\n",
    "print(dataset.shape) # (1742, 1024, 52)\n",
    "# split dataset\n",
    "train_set = dataset[0:1642]\n",
    "valid_set = dataset[1642:1692]\n",
    "test_set = dataset[1692:1742]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa4f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb843fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input layers\n",
    "input_feature = tf.keras.layers.Input(shape=[1024, 50], name = 'input_feature')\n",
    "input_mask = tf.keras.layers.Input(shape=[1024,], name = 'input_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7843c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 1024, 50)]        0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024, 512)         26112     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1024, 256)         131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1024, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024, 512)         131584    \n",
      "                                                                 \n",
      " output_MLP (Dense)          (None, 1024, 1024)        525312    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 815,360\n",
      "Trainable params: 814,848\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1 test MLP\n",
    "# build model\n",
    "hidden_1 = tf.keras.layers.Dense(512, activation='relu')(input_feature)\n",
    "hidden_2 = tf.keras.layers.Dense(256, activation='relu')(hidden_1)\n",
    "drop1 = tf.keras.layers.Dropout(0.3)(hidden_2)\n",
    "hidden_3 = tf.keras.layers.BatchNormalization()(drop1)\n",
    "hidden_4 = tf.keras.layers.Dense(512, activation='relu')(hidden_3)\n",
    "output = tf.keras.layers.Dense(1024, activation='relu', name = 'output_MLP')(hidden_4)\n",
    "model_MLP = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_MLP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3bd27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 1024, 50)]        0         \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 1018, 32)          11232     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 1018, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 1018, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 509, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 16288)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2048)              33359872  \n",
      "                                                                 \n",
      " output_CNN (Dense)          (None, 1024)              2098176   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,469,408\n",
      "Trainable params: 35,469,344\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2 test CNN\n",
    "# build model\n",
    "hidden_1 = tf.keras.layers.Conv1D(32, 5, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_1 = tf.keras.layers.BatchNormalization()(hidden_1)\n",
    "hidden_1 = tf.keras.layers.Activation('relu')(hidden_1)\n",
    "hidden_1 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_1)\n",
    "hidden_2 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(hidden_1)\n",
    "hidden_2 = tf.keras.layers.BatchNormalization()(hidden_2)\n",
    "hidden_2 = tf.keras.layers.Activation('relu')(hidden_2)\n",
    "hidden_2 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_2)\n",
    "hidden_3 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_3 = tf.keras.layers.BatchNormalization()(hidden_3)\n",
    "hidden_3 = tf.keras.layers.Activation('relu')(hidden_3)\n",
    "hidden_3 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_3)\n",
    "hidden_3 = tf.keras.layers.Flatten()(hidden_3)\n",
    "output = tf.keras.layers.Dense(2048, activation='relu')(hidden_3)\n",
    "output = tf.keras.layers.Dense(1024, activation='relu', name = 'output_CNN')(output)\n",
    "model_CNN = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d623419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 1024, 50)]        0         \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 1024, 32)          2656      \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, 1024, 32)          2080      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 1024, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               16777728  \n",
      "                                                                 \n",
      " output_RNN (Dense)          (None, 1024)              525312    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,307,904\n",
      "Trainable params: 17,307,840\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3 test RNN\n",
    "# build model\n",
    "units = 32\n",
    "rnn = tf.keras.layers.SimpleRNN(units,return_sequences=True)(input_feature)\n",
    "rnn = tf.keras.layers.SimpleRNN(units,return_sequences=True)(rnn)\n",
    "rnn = tf.keras.layers.BatchNormalization()(rnn)\n",
    "rnn = tf.keras.layers.Flatten()(rnn)\n",
    "#print('bet_cnn.get_shape()', rnn.get_shape())\n",
    "rnn = tf.keras.layers.Dense(512, activation='relu')(rnn)\n",
    "output = tf.keras.layers.Dense(1024, activation='relu', name = 'output_RNN')(rnn)\n",
    "model_RNN = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c17505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 1024, 50)]        0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1024, 32)          10624     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1024, 32)          8320      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 1024, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               16777728  \n",
      "                                                                 \n",
      " output_LSTM (Dense)         (None, 1024)              525312    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,322,112\n",
      "Trainable params: 17,322,048\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4 test LSTM\n",
    "# build model\n",
    "units = 32\n",
    "lstm = tf.keras.layers.LSTM(units, return_sequences=True)(input_feature)\n",
    "lstm = tf.keras.layers.LSTM(units, return_sequences=True)(lstm)\n",
    "lstm = tf.keras.layers.BatchNormalization()(lstm)\n",
    "lstm = tf.keras.layers.Flatten()(lstm)\n",
    "#print('lstm.get_shape()', lstm.get_shape())\n",
    "lstm = tf.keras.layers.Dense(512, activation='relu')(lstm)\n",
    "output = tf.keras.layers.Dense(1024, activation='relu', name = 'output_LSTM')(lstm)\n",
    "model_LSTM = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f4fa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 1024, 50)]        0         \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 1024, 64)         21248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 1024, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 1024, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               33554944  \n",
      "                                                                 \n",
      " output_BiLSTM (Dense)       (None, 1024)              525312    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,126,592\n",
      "Trainable params: 34,126,464\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 5 test BiLSTM\n",
    "units = 32\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(input_feature)\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(lstm)\n",
    "lstm = tf.keras.layers.BatchNormalization()(lstm)\n",
    "lstm = tf.keras.layers.Flatten()(lstm)\n",
    "#print('lstm.get_shape()', lstm.get_shape())\n",
    "lstm = tf.keras.layers.Dense(512, activation='relu')(lstm)\n",
    "output = tf.keras.layers.Dense(1024, activation='relu', name = 'output_BiLSTM')(lstm)\n",
    "model_BiLSTM = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6ec4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_3.get_shape() (None, 509, 32)\n",
      "lstm.get_shape() (None, 32576)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 1024, 50)]        0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 1018, 32)          11232     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1018, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 1018, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 509, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 509, 64)          16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 509, 64)          24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 509, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 32576)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               16679424  \n",
      "                                                                 \n",
      " output_CNN_BiLSTM (Dense)   (None, 1024)              525312    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,257,824\n",
      "Trainable params: 17,257,632\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6 test CNN+BiLSTM\n",
    "units = 32\n",
    "hidden_1 = tf.keras.layers.Conv1D(32, 5, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_1 = tf.keras.layers.BatchNormalization()(hidden_1)\n",
    "hidden_1 = tf.keras.layers.Activation('relu')(hidden_1)\n",
    "hidden_1 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_1)\n",
    "hidden_2 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(hidden_1)\n",
    "hidden_2 = tf.keras.layers.BatchNormalization()(hidden_2)\n",
    "hidden_2 = tf.keras.layers.Activation('relu')(hidden_2)\n",
    "hidden_2 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_2)\n",
    "hidden_3 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_3 = tf.keras.layers.BatchNormalization()(hidden_3)\n",
    "hidden_3 = tf.keras.layers.Activation('relu')(hidden_3)\n",
    "hidden_3 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_3)\n",
    "#print('hidden_3.get_shape()', hidden_3.get_shape())\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(hidden_3)\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(lstm)\n",
    "lstm = tf.keras.layers.BatchNormalization()(lstm)\n",
    "lstm = tf.keras.layers.Flatten()(lstm)\n",
    "#print('lstm.get_shape()', lstm.get_shape())\n",
    "lstm = tf.keras.layers.Dense(512, activation='relu')(lstm)\n",
    "output = tf.keras.layers.Dense(1024, activation='relu', name = 'output_CNN_BiLSTM')(lstm)\n",
    "model_CNN_BiLSTM = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_CNN_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d9c7e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_mask (InputLayer)        [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " tf.math.equal_1 (TFOpLambda)   (None, 1024)         0           ['input_mask[0][0]']             \n",
      "                                                                                                  \n",
      " input_feature (InputLayer)     [(None, 1024, 50)]   0           []                               \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 1024)         0           ['tf.math.equal_1[0][0]']        \n",
      "                                                                                                  \n",
      " token_and_position_embedding_1  (None, 1024, 64)    65606       ['input_mask[0][0]',             \n",
      "  (TokenAndPositionEmbedding)                                     'input_feature[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 1, 1, 1024)  0           ['tf.cast_1[0][0]']              \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " transformer_block_2 (Transform  (None, 1024, 64)    25216       ['token_and_position_embedding_1[\n",
      " erBlock)                                                        0][0]',                          \n",
      "                                                                  'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " transformer_block_3 (Transform  (None, 1024, 64)    25216       ['transformer_block_2[0][0]',    \n",
      " erBlock)                                                         'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 65536)        0           ['transformer_block_3[0][0]']    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 2048)         134219776   ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " output_Transformer (Dense)     (None, 1024)         2098176     ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 136,433,990\n",
      "Trainable params: 136,368,454\n",
      "Non-trainable params: 65,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 7 test Transformer\n",
    "from utils.Transformer import MultiHeadSelfAttention\n",
    "from utils.Transformer import TransformerBlock\n",
    "from utils.Transformer import TokenAndPositionEmbedding\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return  seq[:, tf.newaxis, tf.newaxis, :]# (batch_size, 1, 1, seq_len)\n",
    "\n",
    "maxlen = 1024\n",
    "vocab_size = 5\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "ff_dim = 64\n",
    "pos_embed_dim = 64\n",
    "seq_embed_dim = 14\n",
    "num_heads = 4\n",
    "\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim, pos_embed_dim, seq_embed_dim)\n",
    "trans_block_1 = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "trans_block_2 = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "\n",
    "mask = create_padding_mask(input_mask)\n",
    "embedding = embedding_layer([input_mask, input_feature])\n",
    "embedding = trans_block_1(embedding, mask)\n",
    "embedding = trans_block_2(embedding, mask)\n",
    "#print('embedding.get_shape()', embedding.get_shape())\n",
    "\n",
    "transformer = tf.keras.layers.Flatten()(embedding)\n",
    "transformer = tf.keras.layers.Dense(2048, activation='relu')(transformer)\n",
    "output = tf.keras.layers.Dense(1024, activation='relu', name = 'output_Transformer')(transformer)\n",
    "model_Transformer = tf.keras.models.Model(inputs=[input_feature,input_mask], outputs=output)\n",
    "model_Transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d58def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

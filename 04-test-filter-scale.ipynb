{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73893903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1742\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset name list\n",
    "import os\n",
    "hhm_path = 'data/hhblits_example/'\n",
    "pdb_path = 'data/pdb_example/'\n",
    "hhm_path_files = os.listdir(hhm_path)  \n",
    "name_list = []\n",
    "for fi in hhm_path_files: \n",
    "    hhm_name = fi.split('.')[0]\n",
    "    name_list.append(hhm_name)\n",
    "print(len(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c86e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot dict for proteins\n",
    "import numpy as np\n",
    "eyes = np.eye(20)\n",
    "protein_dict = {'C':eyes[0], 'D':eyes[1], 'S':eyes[2], 'Q':eyes[3], 'K':eyes[4],\n",
    "        'I':eyes[5], 'P':eyes[6], 'T':eyes[7], 'F':eyes[8], 'N':eyes[9],\n",
    "        'G':eyes[10], 'H':eyes[11], 'L':eyes[12], 'R':eyes[13], 'W':eyes[14],\n",
    "        'A':eyes[15], 'V':eyes[16], 'E':eyes[17], 'Y':eyes[18], 'M':eyes[19]}\n",
    "#print(protein_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2175aadc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1007941, 61, 52)\n",
      "(1007941,)\n"
     ]
    }
   ],
   "source": [
    "# generate sliding window dataset, size = 61 (30+1+30)\n",
    "window_length = 61\n",
    "shhm_path = 'data/shhm_data/5A_simple_average_shhm/'\n",
    "all_sample_x = []\n",
    "all_sample_y = []\n",
    "t = int((window_length - 1) / 2)\n",
    "with open(\"data/dataset_alphafold.txt\") as file:\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        label_list = []\n",
    "        if(line[0] == '>'):\n",
    "            uniprot_id = line[1:].strip()\n",
    "            seq = file.readline().strip()\n",
    "            label = file.readline().strip()\n",
    "            seq_len = len(seq)\n",
    "            feature_matrix = np.zeros([seq_len + 2 * t, 52], float) # 20+30+1+1,onehot+spacehhblits+noseq+mask\n",
    "            shhm_matrix = np.loadtxt(shhm_path + uniprot_id + \".shhm\")\n",
    "            # check padding\n",
    "            for i in range(feature_matrix.shape[0]):\n",
    "                if(i < t):\n",
    "                    feature_matrix[i][-2] = 1 #noseq\n",
    "                elif(i >= seq_len + t):\n",
    "                    feature_matrix[i][-2] = 1 #noseq\n",
    "                else:\n",
    "                    feature_matrix[i,0:20] = protein_dict[seq[i - t]]\n",
    "                    feature_matrix[i,20:50] = shhm_matrix[i - t,:]\n",
    "                    feature_matrix[i,-1] = 1 # mask\n",
    "        #print(feature_matrix.shape) # seq_len + 2 * t, 52\n",
    "        # sliding window\n",
    "        top = 0\n",
    "        buttom = window_length\n",
    "        while(buttom <= feature_matrix.shape[0]):\n",
    "            all_sample_x.append(feature_matrix[top:buttom])            \n",
    "            top += 1\n",
    "            buttom += 1\n",
    "        for i in range(seq_len):\n",
    "            all_sample_y.append(int(label[i]))\n",
    "        #print(np.array(sample_list).shape)\n",
    "        #print(np.array(label_list).shape)\n",
    "        line = file.readline()        \n",
    "all_sample_x = np.array(all_sample_x)\n",
    "all_sample_y = np.array(all_sample_y)\n",
    "print(all_sample_x.shape)\n",
    "print(all_sample_y.shape)\n",
    "np.save(\"data/dataset_5A_simple_average_shhm_slidingwindow_x.npy\", all_sample_x)\n",
    "np.save(\"data/dataset_5A_simple_average_shhm_slidingwindow_y.npy\", all_sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa4f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb843fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input layers\n",
    "input_feature = tf.keras.layers.Input(shape=[61, 51], name = 'input_feature')\n",
    "input_mask = tf.keras.layers.Input(shape=[61,], name = 'input_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7843c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 61, 51)]          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 61, 512)           26624     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 61, 256)           131328    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 61, 256)           0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 61, 256)          1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 61, 128)           32896     \n",
      "                                                                 \n",
      " output_MLP (Dense)          (None, 61, 2)             258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 192,130\n",
      "Trainable params: 191,618\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1 test MLP\n",
    "# build model\n",
    "hidden_1 = tf.keras.layers.Dense(512, activation='relu')(input_feature)\n",
    "hidden_2 = tf.keras.layers.Dense(256, activation='relu')(hidden_1)\n",
    "drop1 = tf.keras.layers.Dropout(0.3)(hidden_2)\n",
    "hidden_3 = tf.keras.layers.BatchNormalization()(drop1)\n",
    "hidden_4 = tf.keras.layers.Dense(128, activation='relu')(hidden_3)\n",
    "output = tf.keras.layers.Dense(2, activation='softmax', name = 'output_MLP')(hidden_4)\n",
    "model_MLP = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_MLP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3bd27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 61, 51)]          0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 55, 32)            11456     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 55, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 55, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 27, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 864)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               110720    \n",
      "                                                                 \n",
      " output_CNN (Dense)          (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,562\n",
      "Trainable params: 122,498\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2 test CNN\n",
    "# build model\n",
    "hidden_1 = tf.keras.layers.Conv1D(32, 5, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_1 = tf.keras.layers.BatchNormalization()(hidden_1)\n",
    "hidden_1 = tf.keras.layers.Activation('relu')(hidden_1)\n",
    "hidden_1 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_1)\n",
    "hidden_2 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(hidden_1)\n",
    "hidden_2 = tf.keras.layers.BatchNormalization()(hidden_2)\n",
    "hidden_2 = tf.keras.layers.Activation('relu')(hidden_2)\n",
    "hidden_2 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_2)\n",
    "hidden_3 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_3 = tf.keras.layers.BatchNormalization()(hidden_3)\n",
    "hidden_3 = tf.keras.layers.Activation('relu')(hidden_3)\n",
    "hidden_3 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_3)\n",
    "hidden_3 = tf.keras.layers.Flatten()(hidden_3)\n",
    "output = tf.keras.layers.Dense(128, activation='relu')(hidden_3)\n",
    "output = tf.keras.layers.Dense(2, activation='softmax', name = 'output_CNN')(output)\n",
    "model_CNN = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d623419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 61, 51)]          0         \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 61, 32)            2688      \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 61, 32)            2080      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 61, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1952)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               249984    \n",
      "                                                                 \n",
      " output_RNN (Dense)          (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 255,138\n",
      "Trainable params: 255,074\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3 test RNN\n",
    "# build model\n",
    "units = 32\n",
    "rnn = tf.keras.layers.SimpleRNN(units,return_sequences=True)(input_feature)\n",
    "rnn = tf.keras.layers.SimpleRNN(units,return_sequences=True)(rnn)\n",
    "rnn = tf.keras.layers.BatchNormalization()(rnn)\n",
    "rnn = tf.keras.layers.Flatten()(rnn)\n",
    "#print('bet_cnn.get_shape()', rnn.get_shape())\n",
    "rnn = tf.keras.layers.Dense(128, activation='relu')(rnn)\n",
    "output = tf.keras.layers.Dense(2, activation='softmax', name = 'output_RNN')(rnn)\n",
    "model_RNN = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c17505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 61, 51)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 61, 32)            10752     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 61, 32)            8320      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 61, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1952)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               249984    \n",
      "                                                                 \n",
      " output_LSTM (Dense)         (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,442\n",
      "Trainable params: 269,378\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4 test LSTM\n",
    "# build model\n",
    "units = 32\n",
    "lstm = tf.keras.layers.LSTM(units, return_sequences=True)(input_feature)\n",
    "lstm = tf.keras.layers.LSTM(units, return_sequences=True)(lstm)\n",
    "lstm = tf.keras.layers.BatchNormalization()(lstm)\n",
    "lstm = tf.keras.layers.Flatten()(lstm)\n",
    "#print('lstm.get_shape()', lstm.get_shape())\n",
    "lstm = tf.keras.layers.Dense(128, activation='relu')(lstm)\n",
    "output = tf.keras.layers.Dense(2, activation='softmax', name = 'output_LSTM')(lstm)\n",
    "model_LSTM = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47f4fa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 61, 51)]          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 61, 64)           21504     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 61, 64)           24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 61, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3904)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               499840    \n",
      "                                                                 \n",
      " output_BiLSTM (Dense)       (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 546,690\n",
      "Trainable params: 546,562\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 5 test BiLSTM\n",
    "units = 32\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(input_feature)\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(lstm)\n",
    "lstm = tf.keras.layers.BatchNormalization()(lstm)\n",
    "lstm = tf.keras.layers.Flatten()(lstm)\n",
    "#print('lstm.get_shape()', lstm.get_shape())\n",
    "lstm = tf.keras.layers.Dense(128, activation='relu')(lstm)\n",
    "output = tf.keras.layers.Dense(2, activation='softmax', name = 'output_BiLSTM')(lstm)\n",
    "model_BiLSTM = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6ec4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_feature (InputLayer)  [(None, 61, 51)]          0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 55, 32)            11456     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 55, 32)           128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 55, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 27, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 27, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 27, 64)           24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 27, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1728)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               221312    \n",
      "                                                                 \n",
      " output_CNN_BiLSTM (Dense)   (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 274,882\n",
      "Trainable params: 274,690\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6 test CNN+BiLSTM\n",
    "units = 32\n",
    "hidden_1 = tf.keras.layers.Conv1D(32, 5, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_1 = tf.keras.layers.BatchNormalization()(hidden_1)\n",
    "hidden_1 = tf.keras.layers.Activation('relu')(hidden_1)\n",
    "hidden_1 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_1)\n",
    "hidden_2 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(hidden_1)\n",
    "hidden_2 = tf.keras.layers.BatchNormalization()(hidden_2)\n",
    "hidden_2 = tf.keras.layers.Activation('relu')(hidden_2)\n",
    "hidden_2 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_2)\n",
    "hidden_3 = tf.keras.layers.Conv1D(32, 7, kernel_initializer='he_uniform')(input_feature)\n",
    "hidden_3 = tf.keras.layers.BatchNormalization()(hidden_3)\n",
    "hidden_3 = tf.keras.layers.Activation('relu')(hidden_3)\n",
    "hidden_3 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=None)(hidden_3)\n",
    "#print('hidden_3.get_shape()', hidden_3.get_shape())\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(hidden_3)\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, return_sequences=True))(lstm)\n",
    "lstm = tf.keras.layers.BatchNormalization()(lstm)\n",
    "lstm = tf.keras.layers.Flatten()(lstm)\n",
    "#print('lstm.get_shape()', lstm.get_shape())\n",
    "lstm = tf.keras.layers.Dense(128, activation='relu')(lstm)\n",
    "output = tf.keras.layers.Dense(2, activation='softmax', name = 'output_CNN_BiLSTM')(lstm)\n",
    "model_CNN_BiLSTM = tf.keras.models.Model(inputs=input_feature, outputs=output)\n",
    "model_CNN_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d9c7e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_mask (InputLayer)        [(None, 61)]         0           []                               \n",
      "                                                                                                  \n",
      " tf.math.equal_1 (TFOpLambda)   (None, 61)           0           ['input_mask[0][0]']             \n",
      "                                                                                                  \n",
      " input_feature (InputLayer)     [(None, 61, 51)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 61)           0           ['tf.math.equal_1[0][0]']        \n",
      "                                                                                                  \n",
      " token_and_position_embedding_1  (None, 61, 64)      65601       ['input_mask[0][0]',             \n",
      "  (TokenAndPositionEmbedding)                                     'input_feature[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 1, 1, 61)    0           ['tf.cast_1[0][0]']              \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " transformer_block_2 (Transform  (None, 61, 64)      25216       ['token_and_position_embedding_1[\n",
      " erBlock)                                                        0][0]',                          \n",
      "                                                                  'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " transformer_block_3 (Transform  (None, 61, 64)      25216       ['transformer_block_2[0][0]',    \n",
      " erBlock)                                                         'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 3904)         0           ['transformer_block_3[0][0]']    \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 128)          499840      ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " output_Transformer (Dense)     (None, 2)            258         ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 616,131\n",
      "Trainable params: 550,595\n",
      "Non-trainable params: 65,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 7 test Transformer\n",
    "from utils.Transformer import MultiHeadSelfAttention\n",
    "from utils.Transformer import TransformerBlock\n",
    "from utils.Transformer import TokenAndPositionEmbedding\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return  seq[:, tf.newaxis, tf.newaxis, :]# (batch_size, 1, 1, seq_len)\n",
    "\n",
    "maxlen = 1024\n",
    "vocab_size = 5\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "ff_dim = 64\n",
    "pos_embed_dim = 64\n",
    "seq_embed_dim = 13\n",
    "num_heads = 4\n",
    "\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim, pos_embed_dim, seq_embed_dim)\n",
    "trans_block_1 = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "trans_block_2 = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "\n",
    "mask = create_padding_mask(input_mask)\n",
    "embedding = embedding_layer([input_mask, input_feature])\n",
    "embedding = trans_block_1(embedding, mask)\n",
    "embedding = trans_block_2(embedding, mask)\n",
    "#print('embedding.get_shape()', embedding.get_shape())\n",
    "\n",
    "transformer = tf.keras.layers.Flatten()(embedding)\n",
    "transformer = tf.keras.layers.Dense(128, activation='relu')(transformer)\n",
    "output = tf.keras.layers.Dense(2, activation='softmax', name = 'output_Transformer')(transformer)\n",
    "model_Transformer = tf.keras.models.Model(inputs=[input_feature,input_mask], outputs=output)\n",
    "model_Transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d58def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
